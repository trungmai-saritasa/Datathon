import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression as lr
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from sklearn import metrics
import plotly.express as px
from sklearn.model_selection import train_test_split, KFold, RepeatedStratifiedKFold, GridSearchCV
import plotly.graph_objects as go
import tensorflow as tf
from tensorflow import keras
from keras import layers
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import r2_score
import streamlit as st

# Config trang -----------------------------------------
st.set_page_config(
    page_title="Model: Linear Regression, K-Means v√† LSTM",
    page_icon="üîÆ",
    layout="wide"
)

df = pd.read_excel("app_build/MDSInc_sales.xlsx")
df_2 = pd.read_csv("app_build/Q12_2014.csv", encoding_errors='ignore')
df_2014 = pd.read_csv("app_build/Q12_2014.csv", encoding_errors='ignore')
df_2014["order_date"] = pd.to_datetime(df["order_date"])
df["order_date"] = pd.to_datetime(df["order_date"])


# T·∫°o ti√™u ƒë·ªÅ -----------------------------------------
col1, col2, col3 = st.columns([1,5,1])

with col1:
    st.write("")
with col2:
    st.image('https://i.pinimg.com/564x/b4/10/1e/b4101eb5bc27a62b8f681bd03da9ffff.jpg')
    st.markdown("<h1 style='text-align: center; color: #B799FF;'>Model: Linear Regression, K-Means v√† LSTM</h1>", unsafe_allow_html=True)
    st.markdown("---", unsafe_allow_html=True)
with col3:
    st.write("")

# Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu -----------------------------------

cleaned_df = df.groupby(["customer_name"]).agg({'sales': 'sum', 'quantity': 'sum', 'shipping_cost': 'sum', 'profit': 'sum', 'discount': 'sum'}).reset_index()
new_df = cleaned_df.drop("customer_name", axis=1).to_numpy()

st.markdown("## Customer Segmentation")

st.info(""" **Ph√¢n lo·∫°i kh√°ch h√†ng:**
- Ta c·∫ßn ph√¢n lo·∫°i kh√°ch h√†ng ƒë·ªÉ t√¨m ki·∫øm ƒë∆∞·ª£c c√°c nh√≥m kh√°ch h√†ng ti·ªÅm nƒÉng ƒë·ªÉ ƒë√°nh m·∫°nh v√†o.

**C·ªôt d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng:**
- Sales: m·ª©c l∆∞∆°ng.
- Profit: l·ª£i nhu·∫≠n
- Quantity: s·ªë l∆∞·ª£ng s·∫£n ph·∫©m
- Shipping_cost: ph√≠ giao h√†ng

**M√¥ h√¨nh:** K-Means.

**ƒê·ªô ƒëo:** Inertia v√† Silhoutte score.
""", icon="‚ÑπÔ∏è")

sum_distances = []
K = range(1,15)
for k in K:
  k_mean = KMeans(n_clusters=k)
  k_mean.fit(new_df)
  sum_distances.append(k_mean.inertia_)

fig = go.Figure()
fig.add_trace(go.Scatter(x=list(K), y=sum_distances, mode='lines+markers', marker=dict(color='blue'), name='Inertia value'))
fig.update_layout(
    title="Elbow method",
    xaxis_title="Number of clusters",
    yaxis_title="Inertia value",
    title_font=dict(size=14)
)
st.plotly_chart(fig)

st.info(""" **Elbow method:**
- S·ª≠ d·ª•ng ph∆∞∆°ng ph√°p n√†y ƒë·ªÉ x√°c ƒë·ªãnh s·ªë ph√¢n c·ª•m t·ªët nh·∫•t cho m√¥ h√¨nh (do K-Means c·∫ßn x√°c ƒë·ªãnh s·ªë c·ª•m tr∆∞·ªõc)
- T√¨m ƒëi·ªÉm c√πi ch·ªè (v·ªã tr√≠ m√† ch·ªâ s·ªë inertia s·∫Ω kh√¥ng c√≤n gi·∫£m ƒë√°ng k·ªÉ)

""", icon="‚ÑπÔ∏è")
st.write("S·ªë ph√¢n c·ª•m t·ªët nh·∫•t: `n = 2`")

k_mean_2 = KMeans(n_clusters=2)
model = k_mean_2.fit(new_df)
result = k_mean_2.labels_

st.write('Silhouette score:', metrics.silhouette_score(new_df, result, metric='euclidean'))

obj = {
    "sales": 0,
    "quantity": 1,
    "discount": 2,
    "profit": 3,
    "shipping_cost": 4,
}
column = obj["quantity"]

col1, col2 = st.columns(2)

with col1:
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=new_df[result == 0, 0], y=new_df[result == 0, column],
        mode='markers', marker=dict(color='lightgreen', symbol='square', size=8),
        name='Segmentation 1'
    ))
    fig.add_trace(go.Scatter(
        x=new_df[result == 1, 0], y=new_df[result == 1, column],
        mode='markers', marker=dict(color='orange', symbol='circle', size=8),
        name='Segmentation 2'
    ))
    fig.add_trace(go.Scatter(
        x=model.cluster_centers_[:, 0], y=model.cluster_centers_[:, column],
        mode='markers', marker=dict(color='red', symbol='star', size=12),
        name='Centroids'
    ))
    fig.update_layout(
        legend=dict(
            traceorder='normal',
        ),
        xaxis=dict(title='Sales'),
        yaxis=dict(title='Quantity'),
        title='Customer Segmentation with Sales and Quantity',
        title_font=dict(size=14),
    )
    st.plotly_chart(fig)

with col2:
    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=new_df[result == 0, 0], y=new_df[result == 0, obj["shipping_cost"]],
        mode='markers', marker=dict(color='lightgreen', symbol='square', size=8),
        name='Segmentation 1'
    ))
    fig.add_trace(go.Scatter(
        x=new_df[result == 1, 0], y=new_df[result == 1, obj["shipping_cost"]],
        mode='markers', marker=dict(color='orange', symbol='circle', size=8),
        name='Segmentation 2'
    ))
    fig.add_trace(go.Scatter(
        x=model.cluster_centers_[:, 0], y=model.cluster_centers_[:, obj["shipping_cost"]],
        mode='markers', marker=dict(color='red', symbol='star', size=12),
        name='Centroids'
    ))
    fig.update_layout(
        legend=dict(
            traceorder='normal',
        ),
        xaxis=dict(title='Sales'),
        yaxis=dict(title='Shipping Cost'),
        title='Customer Segmentation with Sales and Shipping Cost',
        title_font=dict(size=14),
    )
    st.plotly_chart(fig)

st.info(""" **ƒê·ªÅ xu·∫•t:**
- Ph√¢n kh√∫c kh√°ch h√†ng ti√™u d√πng cao c√≥ l∆∞∆°ng doanh thu > 10k, ta c√≥ th·ªÉ ƒë√°nh m·∫°nh v√†o y·∫øu t·ªë n√†y.
- V√≠ d·ª•: X√¢y d·ª±ng h·ªá th·ªëng membership v·ªõi nhi·ªÅu ∆∞u ƒë√£i cho kh√°ch h√†ng c√≥ doanh thu > 10k.

""", icon="‚ÑπÔ∏è")

linear_df = df.groupby(["order_date"]).agg({'sales': 'sum', 'quantity': 'sum', 'shipping_cost': 'sum', 'profit': 'sum', 'discount': 'sum'}).reset_index()
linear_df = linear_df.drop("order_date", axis=1)

y = linear_df.iloc[:, 0]
X = linear_df.iloc[:, 1:]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)

st.markdown("## Find best feature (K-Fold cross validation)")

st.info(""" **T√¨m y·∫øu t·ªë ·∫£nh h∆∞·ªüng nh·∫•t ƒë·∫øn doanh thu:**
- Trong vi·ªác kinh doanh ta lu√¥n mu·ªën bi·∫øt y·∫øu t·ªë n√†o c√≥ t√°c ƒë·ªông l·ªõn nh·∫•t ƒë·∫øn doanh thu c·ªßa c·ª≠a h√†ng, t·ª´ ƒë√≥ khai th√°c ƒë∆∞·ª£c th·∫ø m·∫°nh trong kh√≠a c·∫°nh ƒë√≥.
- Vi·ªác t√¨m ƒë∆∞·ª£c ƒë·∫∑c tr∆∞ng t·ªët nh·∫•t s·∫Ω gi√∫p ta ƒë·ªìng th·ªùi hi·ªÉu ƒë∆∞·ª£c s·ª± t∆∞∆°ng quan gi·ªØa c√°c thu·ªôc t√≠nh.

**Ph∆∞∆°ng ph√°p s·ª≠ d·ª•ng:**
- K-Fold cross validation: ki·ªÉm tra ch√©o

**ƒê·ªô ƒëo ƒë√°nh gi√°:**
- RMSE
""", icon="‚ÑπÔ∏è")

def model_rmse(y_test, y_pred):
    return np.sqrt(np.mean((y_test.ravel() - y_pred.ravel())**2))

def train_each_feature_cross_validation(train, fold = 5):
    feature = {k: 0 for k in train.columns if k != 'sales'}

    for train_split, test_split in KFold(n_splits=fold, shuffle=True).split(train):
        for column in feature.keys():
            feature_train = np.array(train.iloc[train_split].loc[:,[column]])
            label_train = np.array(train.iloc[train_split].loc[:,['sales']])

            feature_test = np.array(train.iloc[test_split].loc[:,[column]])
            label_test = np.array(train.iloc[test_split].loc[:,['sales']])
                
            model = lr().fit(feature_train, label_train)
            pred = model.predict(feature_test)
            rmse = model_rmse(label_test, pred)

            feature[column] += rmse

    return {k: v/fold for k, v in feature.items()}

features = train_each_feature_cross_validation(pd.concat([X_train, y_train], axis=1))
best_feature = min(features, key=features.get)
st.write(f'The best feature in the dataset (most correlated feature to label): `{best_feature}`')
st.write(f"RMSE c·ªßa ƒë·∫∑c tr∆∞ng t·ªët nh·∫•t: `{features[best_feature]}`")

st.info(""" **Nh·∫≠n x√©t:**
- Chi ph√≠ giao h√†ng m·ªõi l√† y·∫øu t·ªë quan tr·ªçng nh·∫•t t√°c ƒë·ªông ƒë·∫øn doanh thu.
- ƒê·ªÉ l√†m r√µ ƒë∆∞·ª£c nh·∫≠n ƒë·ªãnh n√†y, ta c·∫ßn tr·ª±c quan b·∫±ng scatter plot gi·ªØa 2 thu·ªôc t√≠nh n√†y v√† bi·ªÉu ƒë·ªì t∆∞∆°ng quan

**Bi·ªÉu ƒë·ªì:**
- Scatter plot: 2 thu·ªôc t√≠nh `sales` v√† `shipping_cost`
- Bi·ªÉu ƒë·ªì t∆∞∆°ng quan: gi·ªØa c√°c ƒë·∫∑c tr∆∞ng v·ªõi nhau + gi·ªØa 2 thu·ªôc t√≠nh `sales` v√† `shipping_cost` (ph∆∞∆°ng ph√°p spearman)

""", icon="‚ÑπÔ∏è")

st.write("### Scatter plot")

fig = px.scatter(linear_df, x=linear_df[best_feature], y=linear_df['sales'], color=linear_df[best_feature])
fig.update_layout(xaxis_type='log', yaxis_type='log', title="Correlation between best feature and label")
st.plotly_chart(fig)

st.write("### Bi·ªÅu ƒë·ªì t∆∞∆°ng quan")

col1, col2 = st.columns(2)

with col1:
    correlation_matrix = linear_df.corr(method='spearman')
    fig = px.imshow(correlation_matrix, text_auto = True, color_continuous_scale = 'RdYlBu', title="Correlation Heatmap of all features and label")
    st.plotly_chart(fig)
with col2:
    correlation_matrix = linear_df[["sales", "shipping_cost"]].corr(method='spearman')
    fig = px.imshow(correlation_matrix, text_auto = True, color_continuous_scale = 'RdYlBu', title="Correlation Heatmap of Sales and Shipping Cost")
    st.plotly_chart(fig)

st.markdown("## Sales prediction with Linear Regression")

st.info(""" **D·ª± ƒëo√°n doanh thu:**
- D·ª± ƒëo√°n tr∆∞·ªõc ƒë∆∞·ª£c l∆∞·ª£ng doanh thu v·ªõi nh·ªØng ƒë·∫∑c tr∆∞ng cho tr∆∞·ªõc t∆∞·ªüng ch·ª´ng nh∆∞ ƒë∆°n gi·∫£n nh·ªØng l√† 1 ƒëi·ªÅu r·∫•t c·∫ßn thi·∫øt trong vi·ªác ph√¢n t√≠ch d·ªØ li·ªáu.
- C·∫ßn ∆∞·ªõc l∆∞·ª£ng tr∆∞·ªõc doanh thu ƒë·ªÉ ƒë∆∞a ra c√°c quy·∫øt ƒë·ªãnh ƒëi·ªÅu ch·ªânh m√¥ h√¨nh kinh doanh k·ªãp th·ªùi.

**Ph∆∞∆°ng ph√°p s·ª≠ d·ª•ng:**
- Linear Regression: h·ªìi quy tuy·∫øn t√≠nh
- RepeatedStratifiedKFold v√† GridSearchCV: t√¨m ra b·ªô tham s·ªë t·ªët nh·∫•t cho m√¥ h√¨nh LR

**ƒê·ªô ƒëo ƒë√°nh gi√°:**
- MSE
- MAE
- R2 score (Accuracy score)

""", icon="‚ÑπÔ∏è")

cleaned_df = df.groupby(df["order_date"]).agg({'sales': 'sum', 'quantity': 'sum', 'shipping_cost': 'sum', 'profit': 'sum', 'discount': 'sum'}).reset_index()
cleaned_df = cleaned_df.drop(["order_date", "discount", "profit"], axis=1)

fig = go.Figure()
fig.add_trace(go.Scatter(x=cleaned_df.index, y=cleaned_df['sales'], mode='lines', name='Sales in Time Series'))
fig.update_layout(title='Sales in Time Series', xaxis_title='Time', yaxis_title='Sales')
st.plotly_chart(fig)

# cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=10)
# linear_grid = {'positive': [True,False], 
#                 'fit_intercept': [True, False], 
#                 'n_jobs': [1, -1]}
# linear = GridSearchCV( lr(), param_grid=linear_grid,
#                           cv=cv, 
#                           scoring='completeness_score', 
#                           verbose=0)
# linear.fit(X_train, y_train)

model2 = lr().fit(X_train, y_train)
pred = model2.predict(X_test)
result2 = pd.DataFrame(pred, columns=['sales'], index=X_test.index)
st.write('MSE of biased model:', metrics.mean_squared_error(y_test, pred))
st.write('MAE of biased model:', metrics.mean_absolute_error(y_test, pred))
st.write('Model score:', model2.score(X_test, y_test))

st.info(""" **Nh·∫≠n x√©t:**
- M√¥ h√¨nh v·ªõi b·ªô tham s·ªë t·ªët nh·∫•t cho ra accuracy score kh√° cao v·ªõi kho·∫£ng 90%.
- Ch√∫ng ta c·∫ßn ki·ªÉm tra v·ªõi b·ªô d·ªØ li·ªáu doanh thu trong Q1 v√† Q2 nƒÉm 2014.

""", icon="‚ÑπÔ∏è")

df_2 = df_2.groupby(["order_date"]).agg({'sales': 'sum', 'quantity': 'sum', 'shipping_cost': 'sum', 'profit': 'sum', 'discount': 'sum'}).reset_index()
test_df = df_2.drop("order_date", axis=1)

test_X = test_df.iloc[:, 1:]
y_true = test_df.iloc[:, 0]

y_test = model2.predict(test_X)
temp = y_true.to_numpy().reshape(-1, 1)
df_2["order_date"] = pd.to_datetime(df_2["order_date"], format="mixed", dayfirst=True).dt.strftime("%d-%b-%Y")

fig = go.Figure()
fig.add_trace(go.Scatter(x=list(df_2["order_date"].values), y=y_test, mode='lines', name='True Sales', line=dict(color='green')))
fig.add_trace(go.Scatter(x=list(df_2["order_date"].values), y=temp[:, 0], mode='lines', name='Predict Sales', line=dict(color='red')))
fig.update_layout(
    title='Sales prediction vs true values in Q1 and Q2 in 2014',
    xaxis_title='Date',
    yaxis_title='Total sales',
    showlegend=True
)

st.plotly_chart(fig)
st.write("R2 score (Accuracy):", metrics.r2_score(y_true.to_numpy(), y_test))

st.markdown("## Sales prediction with LSTM (RNN)")

st.info(""" **D·ª± ƒëo√°n doanh thu v·ªõi m√¥ h√¨nh Deep Learning:**
- S·ª≠ d·ª•ng Deep Learning s·∫Ω cho ra k·∫øt qu·∫£ t·ªët h∆°n v√† ƒë√°ng tin c·∫≠y h∆°n so v·ªõi Linear Regression l√† m√¥ h√¨nh c√≥ gi√°m s√°t.
- ƒê·ªìng th·ªùi, s·ª≠ d·ª•ng Deep Learning ƒë·ªÉ ƒë·ªëi chi·∫øu k·∫øt qu·∫£ th·ª±c nghi·ªám v·ªõi m√¥ h√¨nh LR tr∆∞·ªõc ƒë√≥.

**M√¥ h√¨nh s·ª≠ d·ª•ng:**
- LSTM (Long short-term memory): m√¥ h√¨nh bi·∫øn th·ªÉ c·ªßa RNN (Recurrent Neural Network)

**L√Ω do s·ª≠ d·ª•ng:**
- RNN ƒë∆∞·ª£c bi·∫øt ƒë·∫øn v·ªõi kh·∫£ nƒÉng d·ª± ƒëo√°n d·ªØ li·ªáu d·∫°ng chu·ªói, ƒë·∫∑c bi·ªát l√† Time Series (d·ªØ li·ªáu d√≤ng th·ªùi gian). LSTM cho ph√©p m√¥ h√¨nh d·ª± ƒëo√°n t·ªët h∆°n khi kh·∫Øc ph·ª•c ƒë∆∞·ª£c nh∆∞·ª£c ƒëi·ªÉm ph·ª• thu·ªôc xa c·ªßa RNN.

**Ph∆∞∆°ng ph√°p ƒë√°nh gi√°:**
- R2 score (Accuracy)

""", icon="‚ÑπÔ∏è")

model_df = StandardScaler().fit_transform(cleaned_df)
train_X, train_y = model_df, model_df[2:, 0]

model = keras.Sequential()
model.add(layers.GRU(
    units = 128,
    input_shape =(5,3)
))
model.add(layers.Dense(units = 1))
model.compile(
    loss='mean_squared_error',
    optimizer=keras.optimizers.Adam(0.001)
)

full_n = train_y.shape[0]
n = int(train_y.shape[0]*0.7)

train = keras.preprocessing.timeseries_dataset_from_array(train_X[:n],train_y[:n],sequence_length=5,batch_size=1) #train
test = keras.preprocessing.timeseries_dataset_from_array(train_X[n:],train_y[n:],sequence_length=5,batch_size=1) #test

test_x = np.array([i[0] for i in test])
test_x.resize(( full_n - n, 5, 3))

model.fit(train)
y_pred = model.predict(test_x)

fig = go.Figure()

fig.add_trace(go.Scatter(x=np.arange(len(train_y[:n])), y=train_y[:n], mode='lines', name='Train'))
fig.add_trace(go.Scatter(x=np.arange(n, full_n), y=train_y[n:], mode='lines', name='Validation'))
fig.add_trace(go.Scatter(x=np.arange(n, full_n), y=y_pred[:, 0], mode='lines', name='Predict'))

fig.update_layout(title='Sales prediction in 2011 to 2013',
                  xaxis_title='Time',
                  yaxis_title='Sales',
                  showlegend=True)

fig.update_xaxes(showgrid=True, zeroline=True)
fig.update_yaxes(showgrid=True, zeroline=True)
st.plotly_chart(fig)

st.write("R2 score:", r2_score( np.array(train_y)[n:],y_pred))

st.info(""" **Nh·∫≠n x√©t:**
- LSTM cho ra ƒë·ªô ch√≠nh x√°c cao h∆°n so v·ªõi Linear Regression, khi d·ª± ƒëo√°n kh·ªõp kho·∫£ng 94% so v·ªõi t·∫≠p validation.
- Ti·∫øp theo c·∫ßn ki·ªÉm tra tr√™n t·∫≠p d·ªØ li·ªáu doanh thu Q1 v√† Q2 c·ªßa nƒÉm 2014.

""", icon="‚ÑπÔ∏è")

df_2014 = df_2014.groupby(["order_date"]).agg({'sales': 'sum', 'quantity': 'sum', 'shipping_cost': 'sum', 'profit': 'sum', 'discount': 'sum'}).reset_index()
dates = df_2014["order_date"].dt.strftime("%d-%b-%Y")

df_2014 = df_2014.drop(["order_date", "discount", "profit"], axis=1)

model_df_2014 = StandardScaler().fit_transform(df_2014)

X, y = model_df_2014, model_df_2014[5:, 0]

another_test = keras.preprocessing.timeseries_dataset_from_array(X,y,sequence_length=5,batch_size=1)

pred = model.predict(another_test)

fig = go.Figure()

fig.add_trace(go.Scatter(x=np.arange(len(dates)-5), y=X[2:-3, 0], mode='lines', name='Test'))
fig.add_trace(go.Scatter(x=np.arange(len(dates)-5), y=pred[:, 0], mode='lines', name='Predict'))

fig.update_layout(title='Sales prediction in Q1 and Q2 of 2014',
                  xaxis_title='Time',
                  yaxis_title='Sales',
                  showlegend=True)

fig.update_xaxes(showgrid=True, zeroline=True)
fig.update_yaxes(showgrid=True, zeroline=True)
st.plotly_chart(fig)

st.write("R2 score:", r2_score(X[2:-3, 0], pred))
