import streamlit as st
import pandas as pd
import numpy as np

from plotly.subplots import make_subplots
import plotly.graph_objects as go
import plotly.express as px

# Config trang -----------------------------------------
st.set_page_config(
    page_title="Dashboard Data Analysis",
    page_icon="üìä",
    layout="wide"
)

df = pd.read_csv('app_build/analysis_df_employee.csv')
df_non_tech = pd.read_csv('app_build/analysis_df.csv')

# T·∫°o ti√™u ƒë·ªÅ -----------------------------------------
col1, col2, col3 = st.columns([1,6,1])

with col1:
    st.write("")
with col2:
    st.image('https://i.pinimg.com/564x/94/cd/95/94cd95a169e5aba95b51c8dad432b997.jpg')
    st.markdown("<h1 style='text-align: center; color: #B799FF;'>DASHBOARD DATA ANALYSIS</h1>", unsafe_allow_html=True)
    st.markdown("---", unsafe_allow_html=True)
with col3:
    st.write("")   

# Plot th·ª© nh·∫•t -----------------------------------------
st.markdown("#### 1. C√°c n·ªÅn t·∫£ng h·ªçc t·∫≠p n√†o ƒë∆∞·ª£c c√°c k·ªπ s∆∞ v√† c√°c h·ªçc sinh tin d√πng nh·∫•t?")
df_student = df_non_tech[df_non_tech['Title'] == 'Student']
df_employee = df.copy()


# Get every platfroms from everyone choice
learning_platfroms_employee = df_employee[['Learning Platforms']].apply(lambda x: 
                                                                        list( map(lambda y:y.strip(),str(x[0]).split('--'))),axis=1)\
                                                                .explode().value_counts().to_frame(name='Vote').drop(index = 'nan')
learning_platfroms = df_student[['Learning Platforms']].apply(lambda x: 
                                                      list( map(lambda y:y.strip(),str(x[0]).split('--'))),axis=1)\
                                                        .explode().value_counts().to_frame(name='Vote').drop(index = 'nan')

# --- drop un useful records
for i in learning_platfroms.index:
    if i.isnumeric():
        learning_platfroms.drop(index = i,inplace=True)
learning_platfroms.drop(index = '-1',inplace=True)

for i in learning_platfroms_employee.index:
    if i.isnumeric():
        learning_platfroms_employee.drop(index = i,inplace=True)
        
learning_platfroms_employee.drop(index = '-1',inplace=True)


# -----

learning_platfroms.reset_index(inplace=True)
learning_platfroms.rename(columns={'index':'Platfrom'},inplace=True)

learning_platfroms_employee.reset_index(inplace=True)
learning_platfroms_employee.rename(columns={'index':'Platfrom'},inplace=True)

# get top 10
learning_platfroms=learning_platfroms.sort_values('Vote',ascending=False).head(10)
learning_platfroms_employee=learning_platfroms_employee.sort_values('Vote',ascending=False).head(10)

# Plot 
fig1 = make_subplots(rows=1,cols=2,
                    specs=[[{"type": "pie"}, {"type": "pie"}]],
                    subplot_titles=("Student", "Employee"))
fig1.add_trace(go.Pie(
     name='',
     values=learning_platfroms['Vote'],
     labels=learning_platfroms['Platfrom'],hole=0.3),  
     row=1, col=1)

fig1.add_trace(go.Pie(
     name='',
     values=learning_platfroms_employee['Vote'],
     labels=learning_platfroms_employee['Platfrom'],hole=0.3),
    row=1, col=2)

fig1.update_layout(height=600, width=1600, title_text="Learning Platforms")
st.plotly_chart(fig1,use_container_width=True,height=800)


st.info("""**Nh·∫≠n x√©t:** V·ªõi 10 n·ªÅn t·∫£ng kh·∫£o s√°t ƒë∆∞·ª£c ch·ªçn nhi·ªÅu nh·∫•t b·ªüi 2 ph√≠a ƒë·ªÅu ƒë∆∞·ª£c gi·ªØa nguy√™n m√† kh√¥ng c√≥ s·ª± xu·∫•t hi·ªán c·ªßa m·ªôt n·ªÅn t·∫£ng n√†o kh√°c ƒë·ªëi v·ªõi b√™n c√≤n l·∫°i, d·∫´n ƒë·∫ßu b·ªüi Coursera v√† Udemy ƒë√£ chi·∫øm m·ªôt ph·∫ßn ph·ªï bi·∫øn r·∫•t l·ªõn ƒë·ªëi v·ªõi nh·ªØng ng∆∞·ªùi ƒë∆∞·ª£c kh·∫£o s√°t khi c√≥ ƒë·∫øn kho·∫£ng 1/3 s·ªë ng∆∞·ªùi l·ª±a ch·ªçn n·ªÅn t·∫£ng n√†y, cho th·∫•y r·∫±ng kh√¥ng c√≥ s·ª± kh√°c bi·ªát l·ªõn gi·ªØa nh·ªØng ng∆∞·ªùi ƒëi h·ªçc v·ªÅ ƒë√£ ƒëi l√†m ·ªü kho·∫£ng m·ª•c n√†y. 
Ngo√†i ra, ta c√≤n th·∫•y vi·ªác h·ªçc ƒë·∫°i h·ªçc kh√¥ng ph·∫£i l√† l·ª±a ch·ªçn ∆∞u ti√™n h√†ng ƒë·∫ßu cho c√°c k·ªπ s∆∞/h·ªçc sinh, thay v√†o ƒë√≥ l√† vi·ªác h·ªçc tr·ª±c tuy·∫øn (c√≥ l·∫Ω l√† do th·ªùi gian h·ªçc t·∫≠p linh ho·∫°t n√™n ƒë∆∞·ª£c nhi·ªÅu ng∆∞·ªùi l·ª±a ch·ªçn).
""", icon="‚ÑπÔ∏è")

st.info("""**Gi·∫£i ph√°p thu h√∫t ng∆∞·ªùi h·ªçc cho nh·ªØng n·ªÅn t·∫£ng h·ªçc t·∫≠p kh√°c**: Qua vi·ªác ph√¢n t√≠ch ra n·ªÅn t·∫£ng h·ªçc t·∫≠p n√†o ƒë∆∞·ª£c nhi·ªÅu h·ªçc sinh/k·ªπ s∆∞ tin d√πng th√¨ nh√≥m nh·∫≠n th·∫•y Coursera c≈©ng nh∆∞ Udemy c√≥ nhi·ªÅu l·ª±a ch·ªçn nh·∫•t. C√°c gi·∫£i ph√°p n√†y ƒë∆∞·ª£c l·ª±a ch·ªçn nhi·ªÅu b·ªüi v√¨: \n
- C√≥ nhi·ªÅu kh√≥a h·ªçc v·ªÅ nhi·ªÅu lƒ©nh v·ª±c kh√°c nhau, t·ª´ l·∫≠p tr√¨nh, thi·∫øt k·∫ø, kinh doanh, marketing, t√†i ch√≠nh, v.v... Dƒ© nhi√™n, vi·ªác h·ªçc ch·ªâ m·ªói Data Science/Machine Learning thu·∫ßn th√¥i l√† ch∆∞a ƒë·ªß, c·∫ßn ph·∫£i k·∫øt h·ª£p nhi·ªÅu ki·∫øn th·ª©c t·ª´ c√°c chuy√™n ng√†nh kh√°c v√†o ƒë·ªÉ l·∫•y ki·∫øn th·ª©c cho vi·ªác ph√¢n t√≠ch d·ªØ li·ªáu t·ª´ ch√∫ng.
- Chi ph√≠ m·ªói kh√≥a h·ªçc r·∫ª ho·∫∑c ƒë·ªÅu mi·ªÖn ph√≠. ƒê·ªëi v·ªõi Udemy, h·ªç c√≥ nh·ªØng ƒë·ª£t gi·∫£m gi√° s√¢u cho nh·ªØng kh√≥a h·ªçc c·ªßa m√¨nh, ng∆∞·ªùi d√πng ch·ªâ c·∫ßn b·ªè m·ªôt kho·∫£n ph√≠ nh·ªè ƒë·ªÉ s·ªü h·ªØu ƒë∆∞·ª£c ch√∫ng. ƒê·ªëi v·ªõi Coursera, c√°c kh√≥a h·ªçc c√≥ h·ªó tr·ª£ t√†i ch√≠nh (mi·ªÖn ph√≠ ho·∫∑c n·ª≠a gi√°,...) hay h·ªçc d·ª± th√≠nh (kh√¥ng l√†m b√†i t·∫≠p, kh√¥ng c√≥ ch·ª©ng ch·ªâ khi h·ªçc xong). Nh·ªØng ƒëi·ªÅu n√†y gi√∫p cho ng∆∞·ªùi h·ªçc ti·∫øp c·∫≠n nhi·ªÅu h∆°n v·ªõi n·ªÅn t·∫£ng n√†y.
- C√°c kh√≥a h·ªçc ƒë∆∞·ª£c t·ªï ch·ª©c b√†i b·∫£n v√† kh√° chuy√™n s√¢u (ƒëa s·ªë l√† c√°c gi·∫£ng vi√™n ƒë·∫°i h·ªçc ƒë·∫øn t·ª´ c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc l·ªõn tr√™n th·∫ø gi·ªõi). \n

Nh∆∞ v·∫≠y, ƒë·ªÉ m·ªôt n·ªÅn t·∫£ng h·ªçc t·∫≠p online thu h√∫t ƒë∆∞·ª£c nhi·ªÅu ng∆∞·ªùi h·ªçc, ta c·∫ßn ph·∫£i c√≥ nh·ªØng y·∫øu t·ªë nh∆∞ tr√™n. V√≠ d·ª•, m·ªôt n·ªÅn t·∫£ng h·ªçc t·∫≠p m·ªõi m·ªü th√¨ c√≥ th·ªÉ √°p d·ª•ng vi·ªác gi·∫£m gi√° theo tu·∫ßn/th√°ng/qu√Ω... ƒë·ªÉ thu h√∫t ƒë∆∞·ª£c nhi·ªÅu ng∆∞·ªùi h·ªçc. Ngo√†i ra, cung c·∫•p nhi·ªÅu ki·∫øn th·ª©c li√™n quan ƒë·∫øn m·ªôt b√†i h·ªçc (bao g·ªìm c√°c chuy√™n ng√†nh/kh√≥a h·ªçc li√™n quan) c√≥ th·ªÉ gi√∫p ng∆∞·ªùi h·ªçc hi·ªÉu s√¢u nh·∫•t c√≥ th·ªÉ. 
""", icon="‚ùì")

#------------------------------------
# Ph√¢n t√≠ch n·ªÅn t·∫£ng h·ªçc t·∫≠p qu·ªëc gia Vi·ªát Nam: 
# Filter Viet Nam
df_student_vi = df_student[df_student['Country'] == 'Viet Nam']
df_employee_vi = df_employee[df_employee['Country'] == 'Viet Nam']

learning_platfroms_employee_vi = df_employee_vi[['Learning Platforms']].apply(lambda x: 
                                                                        list( map(lambda y:y.strip(),str(x[0]).split('--'))),axis=1)\
                                                                .explode().value_counts().to_frame(name='Vote').drop(index = 'nan')
learning_platfroms_vi = df_student_vi[['Learning Platforms']].apply(lambda x: 
                                                      list( map(lambda y:y.strip(),str(x[0]).split('--'))),axis=1)\
                                                        .explode().value_counts().to_frame(name='Vote').drop(index = 'nan')

for i in learning_platfroms_vi.index:
    if i.isnumeric():
        learning_platfroms_vi.drop(index = i,inplace=True)
learning_platfroms_vi.drop(index = '-1',inplace=True)

for i in learning_platfroms_employee_vi.index:
    if i.isnumeric():
        learning_platfroms_employee_vi.drop(index = i,inplace=True)
        
learning_platfroms_employee_vi.drop(index = '-1',inplace=True)

learning_platfroms_vi.reset_index(inplace=True)
learning_platfroms_vi.rename(columns={'index':'Platfrom'},inplace=True)

learning_platfroms_employee_vi.reset_index(inplace=True)
learning_platfroms_employee_vi.rename(columns={'index':'Platfrom'},inplace=True)

# get top 10
learning_platfroms_vi=learning_platfroms_vi.sort_values('Vote',ascending=False).head(10)
learning_platfroms_employee_vi=learning_platfroms_employee_vi.sort_values('Vote',ascending=False).head(10)

# Plot 
fig1vi = make_subplots(rows=1,cols=2,
                    specs=[[{"type": "pie"}, {"type": "pie"}]],
                    subplot_titles=("Student", "Employee"))
fig1vi.add_trace(go.Pie(
     name='',
     values=learning_platfroms_vi['Vote'],
     labels=learning_platfroms_vi['Platfrom'],hole=0.3),  
     row=1, col=1)

fig1vi.add_trace(go.Pie(
     name='',
     values=learning_platfroms_employee_vi['Vote'],
     labels=learning_platfroms_employee_vi['Platfrom'],hole=0.3),
    row=1, col=2)

fig1vi.update_layout(height=600, width=1600, title_text="Learning Platforms In VietNam")
st.plotly_chart(fig1vi,use_container_width=True,height=800)

st.info("""**Nh·∫≠n x√©t**: Qua 10 n·ªÅn t·∫£ng h·ªçc t·∫≠p ƒë∆∞·ª£c kh·∫£o s√°t, ta th·∫•y c√°c k·ªπ s∆∞/sinh vi√™n Vi·ªát Nam h·ªçc qua c√°c n·ªÅn t·∫£ng online nh∆∞ Coursera (ƒë·ªÅu chi·∫øm 27-28%), Kaggle Learn Courses l√† nhi·ªÅu nh·∫•t. Trong khi ƒë√≥, vi·ªác h·ªçc ƒë·∫°i h·ªçc l·∫°i c√≥ s·ª± l·ª±a ch·ªçn √≠t h∆°n nhi·ªÅu. C√≥ l·∫Ω v√¨ chi ph√≠ h·ªçc qu√° cao, b·ªè ra nhi·ªÅu th·ªùi gian v√† c√¥ng s·ª©c h∆°n so v·ªõi c√°c n·ªÅn t·∫£ng online n√™n m·ªõi √≠t l·ª±a ch·ªçn. ƒêi·ªÅu n√†y c√≥ th·ªÉ t·∫°o ra m·ªôt ƒë·ªôi ng≈© k·ªπ s∆∞ √≠t ch·∫•t l∆∞·ª£ng h∆°n so v·ªõi c√°c n∆∞·ªõc kh√°c (t·ª∑ l·ªá h·ªçc ƒë·∫°i h·ªçc cao h∆°n).
""", icon="‚ÑπÔ∏è")
st.info("""**Gi·∫£i ph√°p ƒë·ªÅ xu·∫•t cho c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc thu h√∫t ngu·ªìn sinh vi√™n**: Vi·ªác c√°c n·ªÅn t·∫£ng h·ªçc online chi·∫øm ƒëa s·ªë h∆°n v·ªõi ƒë·ªôi ng≈© k·ªπ s∆∞/sinh vi√™n Vi·ªát Nam c√≥ th·ªÉ l√† m·ªôt c∆° h·ªôi cho c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc. C√°c tr∆∞·ªùng c√≥ th·ªÉ t·∫°o ra c√°c kh√≥a h·ªçc online, ƒë·∫∑c bi·ªát l√† c√°c kh√≥a h·ªçc li√™n quan ƒë·∫øn ML/DS ƒë·ªÉ thu h√∫t ƒë∆∞·ª£c nhi·ªÅu sinh vi√™n bi·∫øt ƒë·∫øn tr∆∞·ªùng c·ªßa m√¨nh h∆°n, v·ª´a cung c·∫•p ki·∫øn th·ª©c chuy√™n m√¥n v·ªÅ lƒ©nh v·ª±c ƒë√≥, v·ª´a c√≥ th·ªÉ linh ho·∫°t gi·ªù gi·∫•c c·ªßa ng∆∞·ªùi h·ªçc. Ngo√†i ra, ƒë·ªÉ c√≥ th·ªÉ t·∫°o ƒë∆∞·ª£c ƒë·ªôi ng≈© k·ªπ s∆∞ ch·∫•t l∆∞·ª£ng h∆°n, mang t√≠nh c·∫°nh tranh cao h∆°n th√¨ c√°c tr∆∞·ªùng n√™n ƒë·∫©y m·∫°nh tuy·ªÉn sinh c≈©ng nh∆∞ gi·∫£m h·ªçc ph√≠ ƒë·ªÉ ng∆∞·ªùi h·ªçc c√≥ th·ªÉ ti·∫øp c·∫≠n ƒë∆∞·ª£c ki·∫øn th·ª©c t·ª´ c√°c tr∆∞·ªùng ƒë·∫°i h·ªçc (v·ªõi chi ph√≠ r·∫ª).
""", icon="‚ùì")

st.markdown("---", unsafe_allow_html=True)
st.markdown("#### 2. C√°c ng√¥n ng·ªØ l·∫≠p tr√¨nh n√†o n√†o ƒë∆∞·ª£c c√°c k·ªπ s∆∞ v√† c√°c h·ªçc sinh s·ª≠ d·ª•ng cho ML/DS?")

Languages_employee = df_employee[['Languages']].apply(lambda x: 
                                                            list( map(lambda y:y.strip(),str(x[0]).split('--'))),axis=1)\
                                                    .explode().value_counts().to_frame(name='Employee')
Languages = df_student[['Languages']].apply(lambda x: 
                                            list( map(lambda y:y.strip(),str(x[0]).split('--'))),axis=1)\
                                            .explode().value_counts().to_frame(name='Student')
# --- drop un useful records
for i in Languages_employee.index:
    if i.isnumeric():
        Languages_employee.drop(index = i,inplace=True)
Languages_employee.drop(index = ['-1','nan'],inplace=True)


for i in Languages.index:
    if i.isnumeric():
        Languages.drop(index = i,inplace=True)
        
Languages.drop(index = ['-1','nan'],inplace=True)

# -----

Languages.reset_index(inplace=True)
Languages.rename(columns={'index':'Languages'},inplace=True)

Languages_employee.reset_index(inplace=True)
Languages_employee.rename(columns={'index':'Languages'},inplace=True)
Languages_use= pd.merge(Languages,Languages_employee,how='inner')

Languages_use_percent  = Languages_use
Languages_use_percent[['Student','Employee']] =  Languages_use[['Student','Employee']]/Languages_use[['Student','Employee']].sum()

# -----
plot2 = go.Figure(data=[go.Bar(
    name = 'Student',
    x = Languages_use_percent['Languages'],
    y = Languages_use_percent['Student'],
   ),
                       go.Bar(
    name = 'Employee',
    x = Languages_use_percent['Languages'],
    y = Languages_use_percent['Employee']
   )
])  
plot2.update_layout(
    xaxis_title="Languages", yaxis_title="Percentage"
)               

st.plotly_chart(plot2, use_container_width= True, height = 800)

st.info("""**Nh·∫≠n x√©t:** Kh√¥ng l·∫° khi Python v·∫´n l√† l·ª±a ch·ªçn h√†ng ƒë·∫ßu c·ªßa lƒ©nh v·ª±c n√†y, v√† c≈©ng kh√¥ng c√≥ nhi·ªÅu kh√°c bi·ªát l·ªõn gi·ªØa ng∆∞·ªùi ƒëi l√†m v√† ng∆∞·ªùi ch∆∞a ƒëi l√†m, ngo·∫°i tr·ª´ vi·ªác ng∆∞·ªùi ƒëi l√†m ta th·∫•y nh·ªânh h∆°n v·ªÅ s·ªë l∆∞·ª£ng c√°c ng√¥n ng·ªØ mang chuy√™n t√≠nh chuy√™n m√¥n 'kh√° h∆°n' nh∆∞ R, Bash, SQL, Scala, VBA, ... trong khi nh·ªØng ng∆∞·ªùi ch∆∞a ƒëi l√†m th√¨ c√≥ xu th·∫ø h·ªçc nh·ªØng ng√¥n ng·ªØ mang t√≠nh 'ƒë·ªÅ c·ª≠' cho ng∆∞·ªùi b·∫Øt ƒë·∫ßu h·ªçc nh∆∞ java, C hay C++.
""", icon="‚ÑπÔ∏è")

# -----
st.markdown("---", unsafe_allow_html=True)
st.markdown("#### 3. Vi·ªác ƒëi l√†m s·∫Ω c√≥ nhi·ªÅu kinh nghi·ªám cho vi·ªác nghi√™n c·ª©u h∆°n hay kh√¥ng?")

employee_paper = df_employee['Published Papers'].value_counts().to_frame()
not_employee_paper = df_non_tech['Published Papers'].value_counts().to_frame() - employee_paper

employee_paper.reset_index(inplace=True)
not_employee_paper.reset_index(inplace=True)

fig3 = make_subplots(rows=1,cols=2,
                    specs=[[{"type": "pie"}, {"type": "pie"}]],
                    subplot_titles=("Employee","Unemployment"))
fig3.add_trace(go.Pie(
     name='',
     values=employee_paper['count'],
     labels=employee_paper['Published Papers']),
     row=1, col=1)

fig3.add_trace(go.Pie(
     name='',
     values=not_employee_paper['count'],
     labels=not_employee_paper['Published Papers']),
    row=1, col=2)

fig3.update_layout(height=600, width=1000, title_text="Published Papers")
st.plotly_chart(fig3, use_container_width= True, height = 800)

st.info("""**Nh·∫≠n x√©t:** Ta c√≥ th·ªÉ th·∫•y r·∫±ng ng∆∞·ªùi ƒëi l√†m c√≥ xu h∆∞·ªõng c√≥ nhi·ªÅu b√†i b√°o h∆°n so v·ªõi nh·ªØng ng∆∞·ªùi ch∆∞a ƒëi l√†m. ƒêi·ªÅu n√†y c√≥ th·ªÉ l√† do h·ªç c√≥ nhi·ªÅu kinh nghi·ªám h∆°n, ho·∫∑c c√≥ th·ªÉ l√† do h·ªç c√≥ nhi·ªÅu th·ªùi gian h∆°n ƒë·ªÉ nghi√™n c·ª©u. 
Ngo√†i ra, ta c√≥ th·ªÉ th·∫•y ƒë∆∞·ª£c vi·ªác c√≥ b√†o b√°o publish hay kh√¥ng c≈©ng c√≥ m·ªôt ph·∫ßn ·∫£nh h∆∞·ªüng ƒë·∫øn kh·∫£ nƒÉng c√≥ vi·ªác c·ªßa nh·ªØng ng∆∞·ªùi kh·∫£o s√°t khi ƒëa ph·∫ßn nh·ªØng ng∆∞·ªùi ch∆∞a c√≥ vi·ªác c≈©ng ch∆∞a c√≥ b√†i b√°o publish, tuy nhi√™n vi·ªác n√†y th√¨ kh√¥ng mang t√≠nh b·∫Øt bu·ªôc v√¨ khi ta xem nh·ªØng kh·∫£o s√°t th√¨ s·ªë ng∆∞·ªùi c√≥ vi·ªác th√¨ s·ªë l∆∞·ª£ng ng∆∞·ªùi kh√¥ng c√≥ b√†i b√°o publish c≈©ng chi·∫øm h∆°n 50%, tuy r·∫±ng kh√¥ng chi·∫øm ph·∫ßn l·ªõn nh∆∞ nh·ªØng ng∆∞·ªùi ch∆∞a c√≥ vi·ªác.""", icon="‚ÑπÔ∏è")


# -----
st.markdown("---", unsafe_allow_html=True)
st.markdown("#### 4. S·ªë nƒÉm kinh nghi·ªám v·ªÅ vi·ªác code ·∫£nh h∆∞·ªüng t·ªõi m·ª©c l∆∞∆°ng ƒë∆∞·ª£c bi·ªÉu hi·ªán nh∆∞ th·∫ø n√†o?")

# Filter out the value "I have never written code":
df_f4 = df[df['Coding Experience'] != 'I have never written code']
coding_exp_counts = df_f4['Coding Experience'].value_counts()

avg_salary = df_f4.groupby('Coding Experience')['Salary'].mean().sort_values()

fig4 = make_subplots(
    rows=1, cols=2,
    column_widths=[0.5, 0.2],
    row_heights=[2],
    subplot_titles=('Average Salary by Coding Experience', 'Coding Experience Distribution'),
    specs=[[{"type": "bar"}, {"type": "pie"}]])

fig4.add_trace(go.Bar(x=avg_salary.index, y=avg_salary.values, name='avg_salary', marker_color='red'), row=1, col=1)

fig4.add_trace(go.Pie(labels=coding_exp_counts.index, values=coding_exp_counts.values, name='coding_exp'), row=1, col=2)

fig4.update_layout(
    title='Coding Experience and Salary',
    xaxis_title="Experience",
    yaxis_title="salary",
    grid=dict(rows=1, columns=2),
    legend_title="Coding Experience",
    template='plotly_white'
)

st.plotly_chart(fig4, use_container_width= True, height = 800)

st.info("""**Nh·∫≠n x√©t:** V·ªõi bi·ªÉu ƒë·ªì c·ªôt th·ª© nh·∫•t, ta c√≥ th·ªÉ nh·∫≠n ra ƒë∆∞·ª£c r·∫±ng kinh nghi·ªám code c√†ng nhi·ªÅu th√¨ ng∆∞·ªùi ƒë√≥ c√≥ m·ª©c l∆∞∆°ng c√†ng cao (tr√™n 30.000 ƒë√¥). Ng∆∞·ª£c l·∫°i v·ªõi ƒëi·ªÅu ƒë√≥ th√¨ s·ªë ng∆∞·ªùi c√≥ kinh nghi·ªám code √≠t h∆°n m·ªôt nƒÉm s·∫Ω c√≥ m·ª©c l∆∞∆°ng kho·∫£ng 6.734 ƒë√¥ ƒë·ªïi l·∫°i. Bi·ªÉu ƒë·ªì h√¨nh tr√≤n b·ªï sung th√™m cho ta th·∫•y ƒë∆∞·ª£c ph·∫ßn trƒÉm ng∆∞·ªùi c√≥ kinh nghi·ªám code √≠t h∆°n m·ªôt nƒÉm chi·∫øm ph·∫ßn l·ªõn (h∆°n 50%), v·∫≠y v·ªõi ng√†nh DS/ML n√≥i chung, nh√¢n l·ª±c tr·∫ª r·∫•t l√† d·ªìi d√†o, nh∆∞ng ng∆∞·ª£c l·∫°i th√¨ nh√¢n l·ª±c c√≥ kinh nghi·ªám r·∫•t √≠t. C√≥ l·∫Ω v√¨ v·∫≠y m√† nh√¨n chung, m·ª©c l∆∞∆°ng ng√†nh n√†y ch·ªâ cao khi c√≥ ƒë·ªß kinh nghi·ªám, b√¨nh th∆∞·ªùng th√¨ kh√¥ng cao l·∫Øm.
""", icon="‚ÑπÔ∏è")

# -----
st.markdown("---", unsafe_allow_html=True)
st.markdown("#### 5. T·ª∑ l·ªá nam/n·ªØ qua c√°c ng√†nh ƒë·∫∑c th√π trong lƒ©nh v·ª±c DS/ML ƒë∆∞·ª£c th·ªÉ hi·ªán nh∆∞ th·∫ø n√†o?")

unwanted = {'Currently not employed', 'Not employed', 'Student'}
title_list = df['Title'].value_counts().nlargest(n=14).index.to_list()
title_list = [e for e in title_list if e not in unwanted]

rate_df = df[df['Title'].isin(title_list)]
rate_df = rate_df.groupby(['Title', 'Gender']).size() / df.groupby('Title').size() * 100
rate_df = rate_df.reset_index(name='Rate')
rate_df = rate_df.sort_values(by='Rate')

rate_df['Gender'] = rate_df['Gender'].replace(['Nonbinary', 'Prefer to self-describe', 'Prefer not to say'], 'Others')

fig5 = go.Figure()

for gender in rate_df['Gender'].unique():
    fig5.add_trace(
        go.Bar(
            x=rate_df[rate_df['Gender'] == gender]['Title'],
            y=rate_df[rate_df['Gender'] == gender]['Rate'],
            name=gender
        )
    )

fig5.update_layout(
    title={
        'text': 'Gender Rate by Occupation',
        'x':0.5,
        'y': 0.96
    },
    xaxis_title='Occupation',
    yaxis_title='Rate (%)',
    template='plotly_white',
    barmode='group',
    legend=dict(
        orientation="h",
        yanchor="middle",
        y=1.05,
        xanchor="center",
        x=0.95
    ),
    bargap=0.2,
    autosize=False,
    width=1250,
    height=600,
    margin=dict(l=50, r=50, t=50, b=50),
    xaxis=dict(type='category'),
    hovermode='x'
)


st.plotly_chart(fig5, use_container_width= True, height = 800)

st.info("""**Nh·∫≠n x√©t**: 
- Trong c·∫£ top 10 ng√†nh ngh·ªÅ hot nh·∫•t, t·ªâ l·ªá nh√¢n vi√™n nam ƒë·ªÅu v∆∞·ª£t tr·ªôi h∆°n nhi·ªÅu so v·ªõi t·ªâ l·ªá nh√¢n vi√™n n·ªØ (trung b√¨nh g·∫•p √≠t nh·∫•t 5 l·∫ßn). ƒêi·ªÅu n√†y cho th·∫•y ng√†nh ngh·ªÅ DS/ML l√† m·ªôt ng√†nh ngh·ªÅ c√≥ t·ªâ l·ªá nam n·ªØ m·∫•t c√¢n ƒë·ªëi nh·∫•t trong s·ªë c√°c ng√†nh ngh·ªÅ kh√°c, c√≥ l·∫Ω v·ªÅ v·∫•n ƒë·ªÅ v·ªÅ s·ª©c kh·ªèe (vi·ªác ng·ªìi m√°y t√≠nh nhi·ªÅu, √≠t v·∫≠n ƒë·ªông) hay v·∫•n ƒë·ªÅ v·ªÅ t√¢m l√Ω (vi·ªác k√©o d√†i v·ªõi c∆∞·ªùng ƒë·ªô cao g√¢y stress n·∫∑ng), gia ƒë√¨nh... ƒë√£ l√†m t·ª∑ l·ªá n·ªØ gi·ªõi gi·∫£m ƒëi ƒë√°ng k·ªÉ.
- Tuy nhi√™n, ƒë·ªëi v·ªõi c√¥ng vi·ªác gi√°o vi√™n/gi√°o s∆∞ (Teacher/Professor), t·ªâ l·ªá nam n·ªØ kh√° c√¢n ƒë·ªëi khi t·ªâ l·ªá gi√°o vi√™n n·ªØ ch·ªâ thua gi√°o vi√™n nam kho·∫£ng h∆°n 10%. V√¨ ƒë·∫∑c th√π c√¥ng vi·ªác n√†y l√† truy·ªÅn ƒë·∫°t ki·∫øn th·ª©c, n√™n c√≥ th·ªÉ n√≥i r·∫±ng ng√†nh ngh·ªÅ n√†y l√† m·ªôt trong nh·ªØng ng√†nh ngh·ªÅ c√≥ t·ªâ l·ªá nam n·ªØ c√¢n ƒë·ªëi nh·∫•t.
- Manager l√† lƒ©nh v·ª±c c√¥ng vi·ªác m√† t·ªâ l·ªá nam v∆∞·ª£t tr·ªôi nh·∫•t so v·ªõi n·ªØ.
""", icon="‚ÑπÔ∏è")

st.info("""**Gi·∫£i ph√°p cho s·ª± m·∫•t c√¢n b·∫±ng gi·ªõi t√≠nh trong ng√†nh ngh·ªÅ DS/ML**:
- ƒê√£i ng·ªô c√¥ng vi·ªác t·ªët cho n·ªØ gi·ªõi, ƒë·∫∑c bi·ªát l√† nh·ªØng ng∆∞·ªùi c√≥ gia ƒë√¨nh, v√≠ d·ª• nh∆∞ cho ph√©p l√†m vi·ªác t·ª´ xa, c√≥ ch·∫ø ƒë·ªô ngh·ªâ thai s·∫£n, ngh·ªâ vi·ªác khi c√≥ con nh·ªè... ƒëi·ªÅu n√†y s·∫Ω gi√∫p cho n·ªØ gi·ªõi c√≥ th·ªÉ l√†m vi·ªác l√¢u d√†i h∆°n trong ng√†nh ngh·ªÅ n√†y.
- T·∫°o ƒëi·ªÅu ki·ªán cho n·ªØ gi·ªõi c√≥ th·ªÉ thƒÉng ti·∫øn trong c√¥ng vi·ªác, v√≠ d·ª• nh∆∞ t·∫°o ƒëi·ªÅu ki·ªán cho n·ªØ gi·ªõi c√≥ th·ªÉ tham gia v√†o c√°c d·ª± √°n l·ªõn, c√≥ th·ªÉ tham gia v√†o c√°c quy·∫øt ƒë·ªãnh l·ªõn trong c√¥ng ty, c√≥ th·ªÉ thƒÉng ti·∫øn l√™n c√°c v·ªã tr√≠ qu·∫£n l√Ω... ƒëi·ªÅu n√†y s·∫Ω gi√∫p cho n·ªØ gi·ªõi c√≥ th·ªÉ c√≥ th√™m ƒë·ªông l·ª±c ƒë·ªÉ ti·∫øp t·ª•c l√†m vi·ªác trong ng√†nh ngh·ªÅ n√†y.
- Ch·∫ø ƒë·ªô thƒÉm kh√°m s·ª©c kh·ªèe t√¢m l√Ω ƒë·ªãnh k·ª≥ cho nh√¢n vi√™n, ƒë·∫∑c bi·ªát l√† nh·ªØng nh√¢n vi√™n n·ªØ gi·ªõi.
""", icon="‚ùì")

# -----
st.markdown("---", unsafe_allow_html=True)
st.markdown("#### 6. M·ªëi quan h·ªá gi·ªØa m·ª©c l∆∞∆°ng v√† ng√†nh ngh·ªÅ:")

title_counts = df['Title'].value_counts().reset_index()
title_counts.columns = ['Title', 'Distribution']

avg_salary = df.groupby('Title')['Salary'].mean().reset_index()

color_palette = ['#FF5733', '#FFC300', '#900C3F', '#008080', '#2ECC71', '#3498DB', '#9B59B6', '#F1948A',
                 '#FF0000', '#00FF00', '#0000FF', '#FFFF00', '#00FFFF', '#FF00FF', '#C0C0C0', '#808080',
                 '#800000', '#808000', '#008000', '#800080', '#008080', '#000080', '#FFFFF0', '#F0FFF0',
                 '#F0FFFF', '#FFFAF0', '#F5F5DC', '#FAEBD7', '#FFEFD5', '#FFE4B5', '#FFE4C4']

hover_text = [
    f"{title_counts['Title'][i]}<br>Average Salary: {avg_salary['Salary'][i]:.2f}K<br>Distribution: {title_counts['Distribution'][i]}"
    for i in range(len(title_counts))
]

fig_scatter6 = go.Figure(data=go.Scatter(
    x=title_counts['Distribution'],
    y=avg_salary['Salary'],
    mode='markers',
    text=hover_text,
    hoverinfo='text',
    marker=dict(
        size=10,
        color=color_palette,
        opacity=0.8,
        line=dict(width=0.5, color='black')
    )
))

fig_scatter6.update_layout(
    title='Job Title Distribution vs Average Salary',
    xaxis_title='Distribution',
    yaxis_title='Average Salary',
    hovermode='closest',
)

st.plotly_chart(fig_scatter6, use_container_width=True)

st.info("""**Nh·∫≠n x√©t**: 
- Data Scientist c√≥ s·ªë l∆∞·ª£ng cao nh·∫•t trong t·∫•t c·∫£ c√°c ng√†nh ngh·ªÅ, trong khi s·ªë l∆∞·ª£ng Data Journalist th√¨ th·∫•p nh·∫•t. Tuy nhi√™n, Data Scientist c√≥ m·ª©c l∆∞∆°ng c√≥ th·ªÉ g·ªçi l√† th·∫•p (t·∫ßm 110000$), c√≥ l·∫Ω v√¨ qu√° nhi·ªÅu nh√¢n l·ª±c n√™n m·ª©c l∆∞∆°ng c·ªßa ng√†nh ngh·ªÅ n√†y b·ªã gi·∫£m xu·ªëng.
- Product/Project Manager c√≥ m·ª©c l∆∞∆°ng trung b√¨nh cao nh·∫•t, trong khi Data Architect c√≥ m·ª©c l∆∞∆°ng trung b√¨nh th·∫•p nh·∫•t. ƒêi·ªÅu n√†y c√≥ th·ªÉ l√† do Data Architect l√† m·ªôt ng√†nh ngh·ªÅ m·ªõi, n√™n m·ª©c l∆∞∆°ng trung b√¨nh c·ªßa n√≥ c√≤n th·∫•p.
""", icon="‚ÑπÔ∏è")

# -----
st.markdown("---", unsafe_allow_html=True)
st.markdown("#### 7. T·ª∑ l·ªá ph√¢n h√≥a ƒë·ªô tu·ªïi theo t·ª´ng qu·ªëc gia qua c√°c nƒÉm trong ng√†nh DS/ML:")

_WIDTH = 900

# L·∫•y c√°c country, get 'China', 'India', 'Viet Nam', 'United States'
df_fil_country = df[df['Country'].isin(["Chinaüá®üá≥", "IndiaüáÆüá≥", "Viet Nam", "U.S.üá∫üá∏"])]


fig7 = px.histogram(df_fil_country,
                    x="Country", color="Age", barmode="stack", histfunc="count",
                    barnorm="percent", animation_frame="Year",
                    width=_WIDTH, height=600,
                    category_orders={"Country": ["Chinaüá®üá≥", "IndiaüáÆüá≥", "Viet Nam", "U.S.üá∫üá∏"],
                                      "Gender":["Man", "Woman", "Prefer not to say", "Nonbinary"],
                                      "Year": range(2018,2022)},
                    title="Gender distribution of people")
fig7.update_xaxes(type='category')
fig7.update_yaxes(title="Percentage of respondents (%)")
st.plotly_chart(fig7, use_container_width=True)

st.info("""**Nh·∫≠n x√©t**:
- Nh∆∞ ta c√≥ th·ªÉ th·∫•y t·ª´ bi·ªÉu ƒë·ªì, t·ªâ l·ªá ph√¢n ho√° ƒë·ªô tu·ªïi theo t·ª´ng qu·ªëc gia ·ªü M·ªπ cao h∆°n r√µ r·ªát so v·ªõi 3 n∆∞·ªõc c√≤n l·∫°i, s·ªë l∆∞·ª£ng ng∆∞·ªùi tham gia cu·ªôc ph·ªèng v·∫•n l√† c√¥ng d√¢n M·ªπ th∆∞·ªùng c√≥ th·ªÉ n·∫±m trong b·∫•t k√¨ ƒë·ªô tu·ªïi n√†o. Trong khi ƒë√≥ Vi·ªát Nam, ·∫§n ƒê·ªô v√† Trung Qu·ªëc chi·∫øm s·ªë ƒë√¥ng l√† nh·ªØng ng∆∞·ªùi c√≥ ƒë·ªô tu·ªïi t·ª´ 18 ƒë·∫øn d∆∞·ªõi 40, ph·∫ßn c√≤n l·∫°i chi·∫øm thi·ªÉu s·ªë.
- N·∫øu ta nh√¨n s√¢u h∆°n qua c√°c nƒÉm t·ª´ 2018 ƒë·∫øn 2022, c√≥ 1 ƒëi·ªÉm chung gi·ªØa 3 qu·ªëc gia Vi·ªát Nam, Trung Qu·ªëc v√† ·∫§n ƒê·ªô l√† c·∫£ s·ªë l∆∞·ª£ng ng∆∞·ªùi thu·ªôc ƒë·ªô tu·ªïi 18-21 c√≥ c√πng xu h∆∞·ªõng tƒÉng d·∫ßn theo t·ª´ng nƒÉm, ƒë·ªânh ƒëi·ªÉm l√† nƒÉm 2021 s·ªë l∆∞·ª£ng ng∆∞·ªùi tham gia cu·ªôc ph·ªèng v·∫•n ·ªü Vi·ªát Nam ƒë·ªô tu·ªïi n√†y chi·∫øm 40%, sau ƒë√≥ l√† ·∫§n ƒê·ªô v·ªõi h∆°n 35% v√† Trung Qu·ªëc v·ªõi 25%, ƒë·ªÅu cao h∆°n c·∫£ 3 nƒÉm tr∆∞·ªõc ƒë√≥. ƒêi·ªÅu n√†y c√≥ th·ªÉ l√Ω gi·∫£i ƒë∆∞·ª£c vi·ªác ng√†y c√†ng c√≥ nhi·ªÅu ng∆∞·ªùi tr·∫ª c√≥ s·ª± h·ª©ng th√∫ v√† tham gia v√†o vi·ªác h·ªçc c≈©ng nh∆∞ l√†m trong m·∫£ng Machine Learning v√† Data Science.
- Ngo√†i ra, ta c≈©ng th·∫•y ƒë∆∞·ª£c r·∫±ng s·ªë l∆∞·ª£ng ng∆∞·ªùi tr·∫£ l·ªùi thu·ªôc ƒë·ªô tu·ªïi 25-29 c≈©ng chi·∫øm ph·∫ßn l·ªõn, nguy√™n nh√¢n l√† v√¨ ƒë√¢y l√† ƒë·ªô tu·ªïi ph√π h·ª£p nh·∫•t v·ªÅ tr√¨nh ƒë·ªô l·∫´n chuy√™n m√¥n trong 2 lƒ©nh v·ª±c Machine Learning v√† Data Science, tuy nhi√™n c√≥ 1 ƒëi·ªÉm th√∫ v·ªã l√† s·ªë l∆∞·ª£ng ng∆∞·ªùi ·ªü ƒë·ªô tu·ªïi n√†y ·ªü M·ªπ th√¨ gi·∫£m d·∫ßn theo t·ª´ng nƒÉm, b·∫Øt ƒë·∫ßu v·ªõi 25% s·ªë ng∆∞·ªùi thu·ªôc ƒë·ªô tu·ªïi n√†y v√†o nƒÉm 2018 nh∆∞ng ch·ªâ c√≤n kho·∫£ng 14% v√†o nƒÉm 2022.
""", icon="‚ÑπÔ∏è")

# -----
st.markdown("---", unsafe_allow_html=True)
st.markdown("#### 8. S·ªë nƒÉm kinh nghi·ªám gi·ªØa nh·ªØng ng∆∞·ªùi trong ng√†nh DS/ML t·ª´ng qu·ªëc gia qua c√°c nƒÉm th·ªÉ hi·ªán nh∆∞ th·∫ø n√†o?")

fig8 = px.histogram(df_fil_country,
                    x="Country", color="Coding Experience", barmode="stack", histfunc="count",
                    barnorm="percent", animation_frame="Year",
                    width=_WIDTH, height=600,
                    category_orders={"Country": ["Chinaüá®üá≥", "IndiaüáÆüá≥", "Viet Nam", "U.S.üá∫üá∏"],
                                      "Gender":["Man", "Woman", "Prefer not to say", "Nonbinary"],
                                      "Year": range(2018,2022)},
                    title="Gender distribution of people",
                )
fig8.update_xaxes(type='category')
fig8.update_yaxes(title="Percentage of respondents (%)")
st.plotly_chart(fig8, use_container_width=True)

st.info("""**Nh·∫≠n x√©t**:
- ƒêi·ªÉm chung gi·ªØa c√°c bi·ªÉu ƒë·ªì xuy√™n su·ªët c√°c nƒÉm t·ª´ 2018 ƒë·∫øn 2022 l√† s·ªë l∆∞·ª£ng ng∆∞·ªùi tham gia tr·∫£ l·ªùi c√≥ d∆∞·ªõi 1 nƒÉm kinh nghi·ªám ·ªü Trung Qu·ªëc, ·∫§n ƒê·ªô v√† Vi·ªát Nam ƒë·ªÅu cao h∆°n so v·ªõi c·∫£ M·ªπ (trong ƒë√≥ cao nh·∫•t l√† Vi·ªát Nam v√†o nƒÉm 2018 v·ªõi 43%)
- S·ªë l∆∞·ª£ng ng∆∞·ªùi c√≥ t·ª´ 1 ƒë·∫øn 5 nƒÉm kinh nghi·ªám trong lƒ©nh v·ª±c Data Science v√† Machine Learning chi·∫øm s·ªë l∆∞·ª£ng ƒë√¥ng ƒë·∫£o nh·∫•t trong cu·ªôc ph·ªèng v·∫•n, t·ªâ l·ªá lu√¥n trong kho·∫£ng 50% cho c·∫£ 4 qu·ªëc gia. ƒêi·ªÅu ƒë√≥ ch·ª©ng t·ªè r·∫±ng ƒë√¢y m·ªõi l√† nh√≥m ng∆∞·ªùi c√≥ ƒë·ªß ki·∫øn th·ª©c chuy√™n m√¥n v√† s·∫Ω mang tr·ªçng s·ªë l·ªõn nh·∫•t ƒë·ªÉ cho ra k·∫øt qu·∫£ kh·∫£o s√°t ch√≠nh x√°c nh·∫•t.
- Ngo√†i ra, c√°c nh√≥m ng∆∞·ªùi c√≤n l·∫°i nh∆∞ nh·ªØng ng∆∞·ªùi c√≥ t·ª´ 5 ƒë·∫øn 10 nƒÉm, 10 ƒë·∫øn 20 nƒÉm ho·∫∑c th·∫≠m ch√≠ h∆°n 20 nƒÉm chi·∫øm t·ªâ l·ªá cao nh·∫•t ·ªü M·ªπ, cao h∆°n h·∫≥n so v·ªõi 3 qu·ªëc gia c√≤n l·∫°i (c·ª• th·ªÉ nh√≥m ng∆∞·ªùi c√≥ t·ª´ 10-20 nƒÉm kinh nghi·ªám ·ªü M·ªπ ƒë·∫°t 14% nƒÉm 2020 v√† 16% c√πng nƒÉm ƒë√≥ cho nh√≥m ng∆∞·ªùi c√≥ tr√™n 20 nƒÉm kinh nghi·ªám), trong khi ƒë√≥ h·∫ßu nh∆∞ nh√≥m ng∆∞·ªùi ƒë√≥ g·∫ßn nh∆∞ kh√¥ng xu·∫•t hi·ªán ·ªü c·∫£ 3 qu·ªëc gia kia.
""", icon="‚ÑπÔ∏è")

#-----
st.markdown("---", unsafe_allow_html=True)
st.markdown("#### 9. M·ª©c thu nh·∫≠p theo gi·ªõi t√≠nh ·ªü t·ª´ng qu·ªëc gia qua c√°c nƒÉm th·ªÉ hi·ªán nh∆∞ th·∫ø n√†o?")

avg_data = df_fil_country[df_fil_country["Gender"].isin(["Man", "Woman"])]
avg_data = avg_data[["Country", "Gender", "Salary", "Year"]]
avg_data = avg_data.dropna(subset=["Gender", "Country", "Salary", "Year"])
avg_data = avg_data.groupby(["Country", "Gender", "Year"], as_index=False).mean()


fig9 = px.bar(avg_data,
            x="Country", y="Salary",
            color="Gender",
            animation_frame="Year",
            barmode="group",
            width=_WIDTH, height=600,
            category_orders={"Country": ["Chinaüá®üá≥", "IndiaüáÆüá≥", "Viet Nam", "U.S.üá∫üá∏"],
                            "Gender":["Man", "Woman"],
                            "Year": range(2018,2022)},
            title="Average yearly compensation of men and women",
            text="Salary")

fig9.update_traces(texttemplate='%{text:.2f}', textposition='outside')
fig9.update_layout(yaxis_range=[0,38000])
fig9.update_yaxes(title="Average yearly compensation (number of Big Macs)")
fig9.update_xaxes(type='category')

st.plotly_chart(fig9, use_container_width=True)

st.info("""**Nh·∫≠n x√©t**:
- V·ªÅ t·ªïng qu√°t, m·ª©c l∆∞∆°ng th∆∞·ªùng ni√™n trung b√¨nh ·ªü 4 qu·ªëc gia qua c√°c nƒÉm c√≥ s·ª± tƒÉng gi·∫£m kh√¥ng h·ªÅ ·ªïn ƒë·ªãnh. Tuy nhi√™n, ƒë√°ng ch√∫ √Ω l√† trung b√¨nh thu nh·∫≠p h·∫±ng nƒÉm ·ªü M·ªπ c·ªßa nam lu√¥n cao h∆°n n·ªØ, l·ªách nhi·ªÅu nh·∫•t l√† trong nƒÉm 2022 v·ªõi h∆°n 35,5k ƒë√¥ cho nam v√† ch·ªâ g·∫ßn 24k cho n·ªØ (l·ªách 11k ƒë√¥).
- ·ªû 3 qu·ªëc gia c√≤n l·∫°i, c√≥ s·ª± thay ƒë·ªïi r√µ r·ªát gi·ªØa t·ª´ng nƒÉm, c√≥ nh·ªØng nƒÉm t·ªïng thu nh·∫≠p h·∫±ng nƒÉm c·ªßa nam cao h∆°n, c√≥ nƒÉm th√¨ c·ªßa n·ªØ cao h∆°n. ƒêi·ªÅu n√†y cho th·∫•y ƒë∆∞·ª£c thu nh·∫≠p ·ªü 3 qu·ªëc gia n√†y th·ª±c s·ª± kh√¥ng ph·∫£i d·ª±a tr√™n gi·ªõi t√≠nh m√† n√≥ ƒë∆∞·ª£c tr·∫£ c√¥ng b·∫±ng th·ª±c l·ª±c v√† m·ª©c ƒë·ªô chuy√™n m√¥n c·ªßa ng∆∞·ªùi l√†m trong ng√†nh Machine Learning v√† Data Science.
""", icon="‚ÑπÔ∏è")

#-----
st.markdown("---", unsafe_allow_html=True)
st.markdown("#### 10. S·ª± ph√¢n b·ªï gi·ªØa c√°c tr√¨nh ƒë·ªô h·ªçc v·∫•n c·ªßa ng∆∞·ªùi tham gia kh·∫£o s√°t ƒë∆∞·ª£c th·ªÉ hi·ªán nh∆∞ th·∫ø n√†o?")

import plotly.figure_factory as ff

z = df.groupby(['Formal Education', 'Age']).size().unstack().fillna(0).astype('int64')
z_data = z.apply(lambda x:np.round(x/x.sum(), 2), axis = 1).to_numpy() # convert to correlation matrix
x = z.columns.tolist()
y = z.index.tolist()

fig10 = ff.create_annotated_heatmap(z_data, x = x, y = y, colorscale = "Viridis", showscale = True)

st.plotly_chart(fig10, use_container_width=True)

st.info("""**Nh·∫≠n x√©t**:  
- Ng∆∞·ªùi trong kho·∫£ng ƒë·ªô tu·ªïi 18 - 21 v·∫´n ƒëang h·ªçc v√† ch∆∞a c√≥ b·∫≥ng c·ª≠ nh√¢n chi·∫øm t·ªâ l·ªá cao nh·∫•t, song song theo ƒë√≥ th√¨ nh·ªØng ng∆∞·ªùi ch∆∞a qua b·∫≠c trung h·ªçc v·∫´n chi·∫øm m·ªôt t·ª∑ l·ªá v·ª´a trong ƒë·ªô tu·ªïi n√†y.
- T·ª´ ƒë·ªô tu·ªïi 22 - 39, t·ªâ l·ªá ng∆∞·ªùi c√≥ b·∫±ng ti·∫øn sƒ© v√† th·∫°c sƒ©, b·∫±ng c·∫•p chuy√™n nghi·ªáp l·∫°i chi·∫øm cao h∆°n t·∫•t c·∫£ c√°c b·∫≠c h·ªçc kh√°c, ƒë·∫∑c bi·ªát l√† ·ªü ƒë·ªô tu·ªïi 30 - 34.
- Ngo√†i ra, c√†ng cao tu·ªïi th√¨ kh√¥ng c√≥ b·∫≠c h·ªçc c·ª• th·ªÉ, c√≥ th·ªÉ h·ªç √≠t tham gia v√†o b√†i kh·∫£o s√°t n√™n kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch.
""", icon="‚ÑπÔ∏è")

#-----
st.markdown("---", unsafe_allow_html=True)

st.markdown("<h5 style='text-align: center; color:green'>DASHBOARD</h5>", unsafe_allow_html=True)

st.markdown("---", unsafe_allow_html=True)

col1, col2 = st.columns(2)

with col1:
    st.markdown("#### Learning Platform Recommendation")
    st.plotly_chart(fig1, use_container_width=True, width=800)
with col2:
    st.markdown("#### Programming Languages Recommendation")
    st.plotly_chart(plot2, use_container_width=True, witdh=800)

col3, col4, col5 = st.columns(3)

with col3:
    st.markdown("#### Age & Gender & Year")
    st.plotly_chart(fig7, use_container_width=True, width=800)
with col4:
    st.markdown("#### Coding Experience & Country & Year")
    st.plotly_chart(fig8, use_container_width=True, width=800)
with col5:
    st.markdown('#### Gender & Country & Year & Salary')
    st.plotly_chart(fig9, use_container_width=True, width=800)

col6, col7 = st.columns(2)

with col6:
    st.markdown("#### Coding Experience & Salary")
    st.plotly_chart(fig4, use_container_width=True, width=800)
with col7: 
    st.markdown("#### Gender & Jobs Title")
    st.plotly_chart(fig5, use_container_width=True, width=800)

st.markdown("#### Salary & Jobs Title")
st.plotly_chart(fig_scatter6, use_container_width=True, width=800)

col8, col9 = st.columns(2)

with col8:
    st.markdown("#### Paper & Worker")
    st.plotly_chart(fig3, use_container_width=True, width=800)
with col9:
    st.markdown("#### Education & Age")
    st.plotly_chart(fig10, use_container_width=True, width=800)